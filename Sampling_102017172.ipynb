{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv(\"C:\\\\Users\\\\Dell\\\\Desktop\\\\Pred_Analysis\\\\Sampling_Assignment-main\\\\Creditcard_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Oversampling\n",
    "os = SMOTE(sampling_strategy='minority',random_state=42)\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x_sample,y_sample=os.fit_resample(x,y)\n",
    "df2=pd.concat([x_sample,y_sample], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Simple Random Sampling\n",
    "sample_srs=(1.96**2)*0.5*(1-0.5)/(0.05**2)\n",
    "df_srs=(df2.sample(int(sample_srs),random_state=42))\n",
    "\n",
    "x_train, x_test, y_train, y_test=train_test_split(df_srs.iloc[:,:-1],df_srs.iloc[:,-1],test_size=0.2,random_state=42)\n",
    "LR = LogisticRegression(max_iter= 2500,random_state=42)\n",
    "RFC = RandomForestClassifier(random_state=42)\n",
    "KNC = KNeighborsClassifier()\n",
    "GBC = GradientBoostingClassifier(random_state=42)\n",
    "DTC = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "LR.fit(x_train,y_train)\n",
    "RFC.fit(x_train,y_train)\n",
    "KNC.fit(x_train,y_train)\n",
    "GBC.fit(x_train,y_train)\n",
    "DTC.fit(x_train,y_train)\n",
    "\n",
    "y_pred1 = LR.predict(x_test)\n",
    "y_pred2 = RFC.predict(x_test)\n",
    "y_pred3 = KNC.predict(x_test)\n",
    "y_pred4 = GBC.predict(x_test)\n",
    "y_pred5 = DTC.predict(x_test)\n",
    "\n",
    "result=[[accuracy_score(y_test, y_pred1),accuracy_score(y_test, y_pred2),accuracy_score(y_test,y_pred3),accuracy_score(y_test,y_pred4),accuracy_score(y_test,y_pred5)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Systematic Random Sampling\n",
    "df_systematic=df2.iloc[[i for i in range(5,1000,2)],:]\n",
    "\n",
    "x_train, x_test, y_train, y_test=train_test_split(df_systematic.iloc[:,:-1],df_systematic.iloc[:,-1],test_size=0.2,random_state=42)\n",
    "LR = LogisticRegression(max_iter= 2500,random_state=42)\n",
    "RFC = RandomForestClassifier(random_state=42)\n",
    "KNC = KNeighborsClassifier()\n",
    "GBC = GradientBoostingClassifier(random_state=42)\n",
    "DTC = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "LR.fit(x_train,y_train)\n",
    "RFC.fit(x_train,y_train)\n",
    "KNC.fit(x_train,y_train)\n",
    "GBC.fit(x_train,y_train)\n",
    "DTC.fit(x_train,y_train)\n",
    "\n",
    "y_pred1 = LR.predict(x_test)\n",
    "y_pred2 = RFC.predict(x_test)\n",
    "y_pred3 = KNC.predict(x_test)\n",
    "y_pred4 = GBC.predict(x_test)\n",
    "y_pred5 = DTC.predict(x_test)\n",
    "\n",
    "mat=[accuracy_score(y_test, y_pred1),accuracy_score(y_test, y_pred2),accuracy_score(y_test,y_pred3),accuracy_score(y_test,y_pred4),accuracy_score(y_test,y_pred5)]\n",
    "result.append(mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#stratified sampling\n",
    "Stratified_Sampling=(1.96**2)*0.3*(1-0.3)/((0.05/2)**2)\n",
    "df_stratified=df2.groupby('Class', group_keys=False).apply(lambda x: x.sample(int(Stratified_Sampling/2),random_state=42))\n",
    "# print(data_stratified)\n",
    "x_train, x_test, y_train, y_test=train_test_split(df_stratified.iloc[:,:-1],df_stratified.iloc[:,-1],test_size=0.2,random_state=42)\n",
    "LR = LogisticRegression(max_iter= 2500,random_state=42)\n",
    "RFC = RandomForestClassifier(random_state=42)\n",
    "KNC = KNeighborsClassifier()\n",
    "GBC = GradientBoostingClassifier(random_state=42)\n",
    "DTC = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "LR.fit(x_train,y_train)\n",
    "RFC.fit(x_train,y_train)\n",
    "KNC.fit(x_train,y_train)\n",
    "GBC.fit(x_train,y_train)\n",
    "DTC.fit(x_train,y_train)\n",
    "\n",
    "y_pred1 = LR.predict(x_test)\n",
    "y_pred2 = RFC.predict(x_test)\n",
    "y_pred3 = KNC.predict(x_test)\n",
    "y_pred4 = GBC.predict(x_test)\n",
    "y_pred5 = DTC.predict(x_test)\n",
    "\n",
    "mat=[accuracy_score(y_test, y_pred1),accuracy_score(y_test, y_pred2),accuracy_score(y_test,y_pred3),accuracy_score(y_test,y_pred4),accuracy_score(y_test,y_pred5)]\n",
    "result.append(mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cluster sampling\n",
    "ClusterSampling=(1.96**2)*0.1*(1-0.1)/((0.05/3)**2)\n",
    "s=set(list(df2['Time']))\n",
    "s1=pd.Series(list(s))\n",
    "df_clustered=(df2[df2['Time'].isin([ i for i in s1.sample(int(ClusterSampling/3),random_state=42)])])\n",
    "\n",
    "x_train, x_test, y_train, y_test=train_test_split(df_clustered.iloc[:,:-1],df_clustered.iloc[:,-1],test_size=0.2,random_state=42)\n",
    "LR = LogisticRegression(max_iter= 2500,random_state=42)\n",
    "RFC = RandomForestClassifier(random_state=42)\n",
    "KNC = KNeighborsClassifier()\n",
    "GBC = GradientBoostingClassifier(random_state=42)\n",
    "DTC = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "LR.fit(x_train,y_train)\n",
    "RFC.fit(x_train,y_train)\n",
    "KNC.fit(x_train,y_train)\n",
    "GBC.fit(x_train,y_train)\n",
    "DTC.fit(x_train,y_train)\n",
    "\n",
    "y_pred1 = LR.predict(x_test)\n",
    "y_pred2 = RFC.predict(x_test)\n",
    "y_pred3 = KNC.predict(x_test)\n",
    "y_pred4 = GBC.predict(x_test)\n",
    "y_pred5 = DTC.predict(x_test)\n",
    "\n",
    "mat=[accuracy_score(y_test, y_pred1),accuracy_score(y_test, y_pred2),accuracy_score(y_test,y_pred3),accuracy_score(y_test,y_pred4),accuracy_score(y_test,y_pred5)]\n",
    "result.append(mat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8831168831168831, 0.974025974025974, 0.7922077922077922, 0.961038961038961, 0.961038961038961], [0.91, 0.95, 0.77, 0.98, 0.95], [0.9224806201550387, 0.9922480620155039, 0.8294573643410853, 0.9844961240310077, 0.9651162790697675], [0.9061224489795918, 0.9959183673469387, 0.8571428571428571, 0.9918367346938776, 0.9755102040816327], [0.915, 1.0, 0.895, 1.0, 0.97]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Quota Sampling\n",
    "df_0=df2[df2['Class']==0].iloc[:500]\n",
    "df_1=df2[df2['Class']==1].iloc[:500]\n",
    "df_quotasampling =pd.concat([df_0 ,df_1], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test=train_test_split(df_quotasampling.iloc[:,:-1],df_quotasampling.iloc[:,-1],test_size=0.2,random_state=42)\n",
    "LR = LogisticRegression(max_iter= 2500,random_state=42)\n",
    "RFC = RandomForestClassifier(random_state=42)\n",
    "KNC = KNeighborsClassifier()\n",
    "GBC = GradientBoostingClassifier(random_state=42)\n",
    "DTC = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "LR.fit(x_train,y_train)\n",
    "RFC.fit(x_train,y_train)\n",
    "KNC.fit(x_train,y_train)\n",
    "GBC.fit(x_train,y_train)\n",
    "DTC.fit(x_train,y_train)\n",
    "\n",
    "y_pred1 = LR.predict(x_test)\n",
    "y_pred2 = RFC.predict(x_test)\n",
    "y_pred3 = KNC.predict(x_test)\n",
    "y_pred4 = GBC.predict(x_test)\n",
    "y_pred5 = DTC.predict(x_test)\n",
    "\n",
    "mat=[accuracy_score(y_test, y_pred1),accuracy_score(y_test, y_pred2),accuracy_score(y_test,y_pred3),accuracy_score(y_test,y_pred4),accuracy_score(y_test,y_pred5)]\n",
    "result.append(mat)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       LogReg  RF Classifier  KN Classifier  GB Classifier  \\\n",
      "Simple Sampling      0.883117       0.974026       0.792208       0.961039   \n",
      "Systematic Sampling  0.910000       0.950000       0.770000       0.980000   \n",
      "Stratified Sampling  0.922481       0.992248       0.829457       0.984496   \n",
      "Cluster Sampling     0.906122       0.995918       0.857143       0.991837   \n",
      "Quota Sampling       0.915000       1.000000       0.895000       1.000000   \n",
      "\n",
      "                     DT Classifier  \n",
      "Simple Sampling           0.961039  \n",
      "Systematic Sampling       0.950000  \n",
      "Stratified Sampling       0.965116  \n",
      "Cluster Sampling          0.975510  \n",
      "Quota Sampling            0.970000  \n"
     ]
    }
   ],
   "source": [
    "res_table=pd.DataFrame(result)\n",
    "res_table = res_table.rename(index={0: 'Simple Sampling', 1: 'Systematic Sampling', 2: 'Stratified Sampling',3: 'Cluster Sampling',4: 'Quota Sampling'})\n",
    "res_table = res_table.rename(columns={0: 'LogReg', 1: 'RF Classifier', 2: 'KN Classifier', 3:'GB Classifier',4:'DT Classifier'})\n",
    "print(res_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier method with Quota Sampling gives the highest accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "maximum=-1#accuracy\n",
    "samp_tech=\"\"\n",
    "ml_model=\"\"\n",
    "for i in range(len(result)):\n",
    "    for j in range(len(result[0])):\n",
    "        if (result[i][j]>maximum):          \n",
    "            if i==0:\n",
    "                samp_tech=\"Simple Random Sampling\"\n",
    "            elif i==1:\n",
    "                samp_tech=\"Systematic Random Sampling\"\n",
    "            elif i==2:\n",
    "                samp_tech=\"Stratified sampling\"\n",
    "            elif i==3:\n",
    "                samp_tech=\"Cluster Sampling\"\n",
    "            elif i==4:\n",
    "                samp_tech=\"Quota Sampling\"\n",
    "            if j==0:\n",
    "                ml_model=\"Logistic Regression\"\n",
    "            elif j==1:\n",
    "                ml_model=\"Random Forest Classifier\"\n",
    "            elif j==2:\n",
    "                ml_model=\"K-Neighbors Classifier\"\n",
    "            elif j==3:\n",
    "                ml_model=\"Gradient Boosting Classifier\"\n",
    "            elif j==4:\n",
    "                ml_model=\"Decision Tree Classifier\"                    \n",
    "            maximum=result[i][j]\n",
    "\n",
    "print(f'{ml_model} method with {samp_tech} gives the highest accuracy {maximum}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76d7c06053c3456e5600312cec90888656fc0ed30c03d8425b9dac6e4fc8e014"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
